{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4aff48e",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Articles\n",
    "\n",
    "- [Oklahoma schools rank 50th in the nation in latest education quality study](https://www.oklahoman.com/story/news/education/2025/07/24/oklahoma-schools-ranked-nearly-the-worst-in-the-nation-in-new-study/85310196007/)\n",
    "- [Public School Rankings by State 2025](https://worldpopulationreview.com/state-rankings/public-school-rankings-by-state)\n",
    "- [Worst School Districts by State 2025](https://worldpopulationreview.com/state-rankings/worst-school-districts-by-state)\n",
    "- [2025 Best School Districts in Massachusetts](https://www.niche.com/k12/search/best-school-districts/s/massachusetts/)\n",
    "- [2025 Best School Districts in California](https://www.niche.com/k12/search/best-school-districts/s/california/)\n",
    "\n",
    "### Palo Alto, CA\n",
    "\n",
    "- [Henry M. Gunn High School](https://gunn.pausd.org/)\n",
    "  - [Website](https://gunn.pausd.org/)\n",
    "  - [Niche.com](https://www.niche.com/k12/henry-m-gunn-high-school-palo-alto-ca/)\n",
    "  - [Yelp.com](https://www.yelp.com/biz/henry-m-gunn-high-school-palo-alto-2?osq=henry+m+gunn+high+school)\n",
    "- [Palo Alto Highschool](https://www.paly.net/)\n",
    "  - [Website](https://www.paly.net/)\n",
    "  - [Niche.com](https://www.niche.com/k12/palo-alto-high-school-palo-alto-ca/)\n",
    "  - [Yelp.com](https://www.yelp.com/biz/palo-alto-high-school-palo-alto?osq=palo+alto+high+school)\n",
    "- [Hope Technology School - Private](https://hopetechschool.org/)\n",
    "  - [Website](https://hopetechschool.org/)\n",
    "  - [Yelp.com](https://www.yelp.com/biz/hope-technology-school-palo-alto-6)\n",
    "- [Palo Alto Middle College High School](https://mc.pausd.org/)\n",
    "  - [Website](https://mc.pausd.org/)\n",
    "  - [Yelp.com](https://www.yelp.com/biz/palo-alto-middle-college-high-school-los-altos-hills?osq=middle+college+high+school)\n",
    "\n",
    "### Oklahoma City, OK\n",
    "\n",
    "- [Boulevard Academy](https://boulevardacademy.edmondschools.net/o/boulevardacademy)\n",
    "  - [Website](https://boulevardacademy.edmondschools.net/o/boulevardacademy)\n",
    "- [Memorial High School](https://memorial.edmondschools.net/o/memorial)\n",
    "  - [Website](https://memorial.edmondschools.net/o/memorial)\n",
    "  - [Niche.com](https://www.niche.com/k12/memorial-high-school-edmond-ok/)\n",
    "  - [Yelp.com](https://www.yelp.com/biz/memorial-high-school-tulsa?osq=memorial+high+school)\n",
    "- [North High School](https://north.edmondschools.net/o/north)\n",
    "- [Santa Fe High School](https://santafe.edmondschools.net/o/santafe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b82d1",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757a46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from text_processing import save_pickle_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdd8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset folder location\n",
    "dataset_folder = Path(\"../datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a16a4aa",
   "metadata": {},
   "source": [
    "## Connect to Reddit API\n",
    "\n",
    "**Note:** Default credentials are stored in the `praw.ini` file. This file must\n",
    "be created for the Reddit API to work. Use the `praw.ini.template` as a\n",
    "reference to create the `praw.ini` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b4cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated as: None\n"
     ]
    }
   ],
   "source": [
    "# default credentials stored in `praw.ini` file\n",
    "try:\n",
    "\n",
    "    reddit = praw.Reddit(\"default\")\n",
    "    print(f\"Authenticated as: {reddit.user.me()}\")\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] Error initializing Reddit instance.\")\n",
    "    print(\"Check that the `praw.ini` is configured correctly. \")\n",
    "    print(f\"Details: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Check for connection\n",
    "# for post in subreddit.hot(limit=5):\n",
    "#     print(post.title, post.score, post.id, post.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969e77c",
   "metadata": {},
   "source": [
    "## Reddit Query Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a50689f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(s: str) -> int:\n",
    "    return len(re.findall(r\"\\w+\", s or \"\"))\n",
    "\n",
    "\n",
    "def comments_to_corpus(submission, min_score=6, min_words=21):\n",
    "    \"\"\"\n",
    "    Extract and filter comments from a Reddit submission.\n",
    "\n",
    "    Iterates through all comments in a submission and keeps only those that meet\n",
    "    both a minimum score threshold and a minimum word count. Each qualifying\n",
    "    comment is returned in two parallel forms:\n",
    "\n",
    "    - \"nested\": [[\"comment1\"], [\"comment2\"], ...]\n",
    "    - \"flat\":   [\"comment1\", \"comment2\", ...]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    submission : praw.models.Submission\n",
    "        Reddit submission object from which to collect comments.\n",
    "    min_score : int, optional, default=6\n",
    "        Minimum upvote score required for a comment to be included.\n",
    "    min_words : int, optional, default=21\n",
    "        Minimum number of words required for a comment to be included.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with two keys:\n",
    "        - \"nested\": list of list of str\n",
    "        - \"flat\":   list of str\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Comments with `[deleted]` or `[removed]` text are skipped.\n",
    "    - Comments with no body text or missing score are excluded.\n",
    "    - `submission.comments.replace_more(limit=0)` is used to ensure that\n",
    "      all comments are fully loaded before filtering.\n",
    "    \"\"\"\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    nested, flat = [], []\n",
    "\n",
    "    for c in submission.comments.list():\n",
    "        body = c.body\n",
    "        if not isinstance(body, str):\n",
    "            continue\n",
    "        body = body.strip()\n",
    "\n",
    "        if body.lower() in (\"[deleted]\", \"[removed]\"):\n",
    "            continue\n",
    "        if c.score is None:\n",
    "            continue\n",
    "\n",
    "        if c.score >= min_score and word_count(body) >= min_words:\n",
    "            nested.append([body])\n",
    "            flat.append(body)\n",
    "\n",
    "    return {\"nested\": nested, \"flat\": flat}\n",
    "\n",
    "\n",
    "def build_df_for_query(\n",
    "    subreddit_name: str,\n",
    "    query: str,\n",
    "    limit=20,\n",
    "    sort=\"relevance\",\n",
    "    time_filter=\"all\",\n",
    "    min_score=6,\n",
    "    min_words=21,\n",
    "):\n",
    "    \"\"\"\n",
    "    Query Reddit submissions and build a DataFrame of post titles and filtered comments.\n",
    "\n",
    "    This function searches a specified subreddit for submissions matching a query\n",
    "    and collects comments from each submission that meet the given thresholds\n",
    "    (minimum score and minimum word count). The comments are returned both as a\n",
    "    nested form (list of single-element lists) and as a flat form (list of strings).\n",
    "    The result is a DataFrame where each row corresponds to one submission.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subreddit_name : str\n",
    "        Name of the subreddit to search (without the \"r/\").\n",
    "    query : str\n",
    "        Search query string to use within the subreddit.\n",
    "    limit : int, optional, default=20\n",
    "        Maximum number of submissions to retrieve.\n",
    "    sort : {\"relevance\", \"hot\", \"top\", \"new\", \"comments\"}, optional, default=\"relevance\"\n",
    "        Sorting method for the search results.\n",
    "    time_filter : {\"all\", \"day\", \"hour\", \"month\", \"week\", \"year\"}, optional, default=\"all\"\n",
    "        Restrict search results to a specific time window.\n",
    "    min_score : int, optional, default=6\n",
    "        Minimum upvote score required for a comment to be included.\n",
    "    min_words : int, optional, default=21\n",
    "        Minimum number of words required for a comment to be included.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with one row per submission and the following columns:\n",
    "\n",
    "        - ``source`` : str\n",
    "            Constant value \"reddit\".\n",
    "        - ``query`` : str\n",
    "            The original search query string.\n",
    "        - ``topic`` : str\n",
    "            Title of the submission.\n",
    "        - ``corpus`` : list of list of str\n",
    "            Nested list of comments (each comment wrapped in a list).\n",
    "        - ``flat_corpus`` : list of str\n",
    "            Flat list of comments.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    sr = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    for subm in sr.search(query, sort=sort, time_filter=time_filter, limit=limit):\n",
    "        try:\n",
    "            comments = comments_to_corpus(\n",
    "                subm, min_score=min_score, min_words=min_words\n",
    "            )\n",
    "\n",
    "            if comments[\"nested\"]:  # only keep submissions with qualifying comments\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"source\": \"reddit\",\n",
    "                        \"query\": query,\n",
    "                        \"topic\": (subm.title or \"\").strip(),\n",
    "                        \"comments_nested\": comments[\"nested\"],\n",
    "                        \"comments_flat\": comments[\"flat\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] {subm.id}: {e}\")\n",
    "            time.sleep(0.2)  # be polite to the API\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def query_builder(district, options):\n",
    "    \"\"\"\n",
    "    Build a Reddit search query string based on district name and topic options.\n",
    "\n",
    "    The function constructs a search query suitable for Reddit's API by combining\n",
    "    the district name (quoted for exact matching) with user-selected topic keywords\n",
    "    joined using logical OR operators inside parentheses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    district : str\n",
    "        Name of the district or area to search for (e.g., \"Palo Alto\").\n",
    "    options : list of str\n",
    "        List of topic keywords to include in the query\n",
    "        (e.g., [\"schools\", \"district\", \"education\"]).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Formatted Reddit search query string.\n",
    "        Example:\n",
    "        '\"Palo Alto\" (schools OR district OR education)'\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - If `district` is empty, only the topic portion is returned.\n",
    "    - If `options` is empty, only the district portion is returned.\n",
    "    - Leading and trailing whitespace in `district` is automatically stripped.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> query_builder(\"Palo Alto\", [\"schools\", \"teachers\"])\n",
    "    '\"Palo Alto\" (schools OR teachers)'\n",
    "\n",
    "    >>> query_builder(\"San Diego\", [])\n",
    "    '\"San Diego\"'\n",
    "    \"\"\"\n",
    "    district_part = f'\"{district.strip()}\"' if district else \"\"\n",
    "\n",
    "    # join topic options with OR inside ()\n",
    "    if options:\n",
    "        options_part = \"(\" + \" OR \".join(options) + \")\"\n",
    "    else:\n",
    "        options_part = \"\"\n",
    "\n",
    "    query = f\"{district_part} {options_part}\".strip()\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "def total_word_count(comments):\n",
    "    \"\"\"\n",
    "    Compute the total number of words across a list of comment strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    comments : list of str\n",
    "        List of comments from which to count words.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Total number of words across all comments.\n",
    "        Returns 0 if `comments` is empty or None.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Each comment is split on whitespace to estimate word count.\n",
    "    - Non-string entries in the list should be cleaned before calling this function.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> total_word_count([\"This is one comment.\", \"This is another.\"])\n",
    "    7\n",
    "\n",
    "    >>> total_word_count([])\n",
    "    0\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    if not comments:\n",
    "        return 0\n",
    "\n",
    "    for comment in comments:\n",
    "        words = comment.split()\n",
    "        total += len(words)\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "def query_and_save(list_of_districts):\n",
    "    for district in list_of_districts:\n",
    "        query = query_builder(district=district, options=query_options)\n",
    "        df = build_df_for_query(\n",
    "            subreddit_name=subreddit_var,\n",
    "            query=query,\n",
    "            limit=LIMIT,\n",
    "            sort=\"relevance\",\n",
    "            time_filter=\"all\",\n",
    "            min_words=MIN_WORD,\n",
    "            min_score=MIN_SCORE,\n",
    "        )\n",
    "        df[\"num_comments\"] = df[\"comments_flat\"].apply(len)\n",
    "        df[\"total_words\"] = df[\"comments_flat\"].apply(total_word_count)\n",
    "        # df.head(5)\n",
    "        file_path = save_pickle_file(\n",
    "            dataframe=df, filename=district, dataset_folder=dataset_folder\n",
    "        )\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2628743",
   "metadata": {},
   "source": [
    "### Variables for Reddit Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ac4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_WORD = 10  # default = 6\n",
    "MIN_SCORE = 5  # default = 21\n",
    "LIMIT = 150  # default = 20\n",
    "\n",
    "subreddit_var = \"all\"\n",
    "query_options = [\n",
    "    \"school\",\n",
    "    \"schools\",\n",
    "    \"district\",\n",
    "    \"education\",\n",
    "    \"homework\",\n",
    "    \"teacher\",\n",
    "    \"teachers\",\n",
    "    \"student\",\n",
    "    \"students\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb80da",
   "metadata": {},
   "source": [
    "## Query and Save Dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2cb85d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as Palo Alto. \n",
      "../datasets/Palo Alto_20251007_235943_reddit.pkl\n",
      "Saved as Oklahoma City. \n",
      "../datasets/Oklahoma City_20251008_000300_reddit.pkl\n"
     ]
    }
   ],
   "source": [
    "districts = [\"Palo Alto\", \"Oklahoma City\"]\n",
    "\n",
    "query_and_save(districts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads509-streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
